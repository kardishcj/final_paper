vec_responses<- 29:41
i_MostImpObst <- 25
i_MostImpResp <- 42
#########        Prepare data for analysis: convert string Lickert Scales to numeric values       #############
# for obstacles
Numeric_obstacles <- Create_NumericLickertScale(d[vec_obstacles], likert_scales, scales)#, as.character(1:dim(array(vec_obstacles))) )
# for responses:
Numeric_responses <- Create_NumericLickertScale(d[vec_responses], likert_scales, scales)#, as.character(1:dim(array(vec_responses)) ) )
# for "most important obstacles"
d_MostImpObst <- data.frame(table(d$X.span.style..font.size..18pt...Of.the.obstacles.identified.above..which.is.the.most.important.obstacle.to.address...span.))
# for "most important responses"
d_MostImpResp <- data.frame(table(d$Of.the.responses.listedÂ.above..which.is.the.most.important.))
# for confidence of achieving 2-degree target
d_2degrees <- data.frame(table(d$How.confident.are.you.that.the.world.can.keep.the.temperature.increase.below.2Â.C...),stringsAsFactors=FALSE)
# for confidence of achieving 1.5-degree target
d_1.5degrees <- data.frame(table(d$How.confident.are.you.that.the.world.can.keep.the.temperature.increase.below.1.5Â.C...))
###########creating the single, go-to matrix w/all numeric data and scales ###################
Tdata <- matrix(,nrow=0, ncol=0)
Tdata$NuLiObst<- Numeric_obstacles #adds obstacles as numeric
Tdata$NuLiResp<- Numeric_responses #adds responses as numeric
Tdata$Char <- d[1:11] #adds background characteristics of respondents
Tdata$MostImpObst <- Create_NumericLickertScale(d[, i_MostImpObst], char_obst, 1:dim(as.matrix(char_obst))[1])
Tdata$MostImpResp <- Create_NumericLickertScale(d[, i_MostImpResp], char_resp, 1:dim(as.matrix(char_resp))[1])
#Recoding "most importants" by changing their levels;
#then placing the recoded data in the new matrix
#Doing something similar for the 2-degree, 1.5-degree, and 3-degree confidence questions.
#NA means "did not answer," then scale goes from 1-5 w/ "very low confidence"
#as 1 and "very high confidence" as 5
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees15 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees2 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees3 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....
#Lastly adding the various scales and short-hands
Tdata$likert_scales <- likert_scales
Tdata$confidence_levels <- confidence_levels
Tdata$short_responses <- short_responses
Tdata$short_obstacles <- short_obstacles
Tdata$scales <- scales
Tdata$char_resp <- char_resp
Tdata$char_obst <- char_obst
Chi_squared(d[12:24], likert_scales)
Chi_squared(Tdata$NuLiObst, likert_scales)
rm(list = ls())
source('lib_Create_NumericLickertScale.R')
source('lib_Correlation_matrix.R')
source('lib_Chi_squared.R')
source('lib_means_sds.R')
source('lib_plot_histograms.R')
source('lib_create_histogram.R')
source('lib_plot_MostImportant.R')
source('lib_degree_targets.R')
#reading in data as an xlsx sheet
d <- read.csv('survey20161209.csv', sep=",",stringsAsFactors = T) #unedited version
#what is the likert scale and in which numeric values should it be converted?
likert_scales <- c("Not Important", "Somewhat Important", "Moderately Important",
"Very Important", "Extremely Important")
scales<- 1:dim(array(likert_scales))
confidence_levels <- c("Very low confidence", "Low confidence", "Medium confidence",
"High confidence", "Very high confidence")
# what are the obstacles/responses written out=
char_obst<- c("(1) Uncertainty about climate change impacts or costs of mitigation",
"(2) Lack of public awareness about the magnitude of climate change impacts",
"(3)Â Different costs and benefits of mitigation across countries",
"(4) Time lag between costs and benefits of mitigation",
"(5) Different understandings of fairness and responsibility" ,
"(6) Concerns over high mitigation costs slowing economic development",
"(7) Uncertainty and risks about low-carbon technologies",
"(8)Â Negative greenhouse-gas emission externality from economic activity",
"(9) Consumerism in society",
"(10) Lack of administrative capacity for climate policy",
"(11) Opposition from special interest groups (for example emission-intensive industries)",
"(12) Global public-good nature of mitigation and free-riding incentives",
"(13) Multitude and complexity ofÂ obstacles",
"There is no \"most important\" obstacle" )
char_resp <- c("(1) More research on climate-change impacts or mitigation costs",
"(2) Intensified communication and education to build public support",
"(3) Financial and technological transfers between countries",
"(4) Compensation to special interest groups (for example, emission-intensive industries)",
"(5) Policies addressing intergenerational conflict (for example, appropriate discounting)",
"(6) Research and developmentÂ for low-carbon technologies",
"(7) Subsidies and standards to deploy low-carbon technologies",
"(8) Carbon pricing",
"(9) Change lifestyles and behaviors within society",
"(10) Strengthening domestic administrative capacity for climate policy",
"(11) Measures to enforce international emissions reductions (for example, trade sanctions)",
"(12) Applying concepts for human development other than growth of GDP",
"(13)Â Coherent and multi-objective policy packages",
"There is no \"most important\" response" )
#short names for obstacles/responses:
short_obstacles <- c("Scientific uncertainty", "Awareness", "Diff costs/benefits",
"Time lag b/t costs/benefits", "Understandings of fairness",
"Development concerns", "Technological uncertainty", "Emissions externality",
"Consumerism", "Lack of capacity", "Special interests",
"Free-riding", "Complexity")
short_responses <- c("More research", "More communication/education", "Monetary/tech transfers",
"Compensation to special interests", "Intragenerational policies",
"Technological R&D", "Tech subsidies/standards", "Carbon pricing",
"Behavior/lifestyle change", "Strengthen capacity", "International enforcement",
"Alt economic measures", "Multi-obj policy packages")
#dropping unneeded columns
d$StartDate <- NULL
d$CollectorID <- NULL
d$EndDate <- NULL
d$Email.Address <- NULL
d$First.Name <- NULL
d$LastName <- NULL
d$IP.Address <- NULL
d$Custom.Data <- NULL
#in which columns are obstacles/responses?
vec_obstacles<- 12:24
vec_responses<- 29:41
i_MostImpObst <- 25
i_MostImpResp <- 42
#########        Prepare data for analysis: convert string Lickert Scales to numeric values       #############
# for obstacles
Numeric_obstacles <- Create_NumericLickertScale(d[vec_obstacles], likert_scales, scales)#, as.character(1:dim(array(vec_obstacles))) )
# for responses:
Numeric_responses <- Create_NumericLickertScale(d[vec_responses], likert_scales, scales)#, as.character(1:dim(array(vec_responses)) ) )
# for "most important obstacles"
d_MostImpObst <- data.frame(table(d$X.span.style..font.size..18pt...Of.the.obstacles.identified.above..which.is.the.most.important.obstacle.to.address...span.))
# for "most important responses"
d_MostImpResp <- data.frame(table(d$Of.the.responses.listedÂ.above..which.is.the.most.important.))
# for confidence of achieving 2-degree target
d_2degrees <- data.frame(table(d$How.confident.are.you.that.the.world.can.keep.the.temperature.increase.below.2Â.C...),stringsAsFactors=FALSE)
# for confidence of achieving 1.5-degree target
d_1.5degrees <- data.frame(table(d$How.confident.are.you.that.the.world.can.keep.the.temperature.increase.below.1.5Â.C...))
###########creating the single, go-to matrix w/all numeric data and scales ###################
Tdata <- matrix(,nrow=0, ncol=0)
Tdata$NuLiObst<- Numeric_obstacles #adds obstacles as numeric
Tdata$NuLiResp<- Numeric_responses #adds responses as numeric
Tdata$Char <- d[1:11] #adds background characteristics of respondents
Tdata$MostImpObst <- Create_NumericLickertScale(d[, i_MostImpObst], char_obst, 1:dim(as.matrix(char_obst))[1])
Tdata$MostImpResp <- Create_NumericLickertScale(d[, i_MostImpResp], char_resp, 1:dim(as.matrix(char_resp))[1])
#Recoding "most importants" by changing their levels;
#then placing the recoded data in the new matrix
#Doing something similar for the 2-degree, 1.5-degree, and 3-degree confidence questions.
#NA means "did not answer," then scale goes from 1-5 w/ "very low confidence"
#as 1 and "very high confidence" as 5
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees15 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees2 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees3 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....
#Lastly adding the various scales and short-hands
Tdata$likert_scales <- likert_scales
Tdata$confidence_levels <- confidence_levels
Tdata$short_responses <- short_responses
Tdata$short_obstacles <- short_obstacles
Tdata$scales <- scales
Tdata$char_resp <- char_resp
Tdata$char_obst <- char_obst
table(d[,25])
table(Tdata$MostImpObst)
table(Tdata$MostImpResp)
is.factor(Tdata$MostImpObst)
library(foreign) #essential for this
library(nnet) #essential for this because it contains the multinom function used
#to actually estimate the model
library(reshape2) #essential for this
Tdata$MostImpObst <- as.factor(Tdata$MostImpObst)
levels(Tdata$MostImpObst)
remove(Tdata)
Tdata <- matrix(,nrow=0, ncol=0)
Tdata$NuLiObst<- Numeric_obstacles #adds obstacles as numeric
Tdata$NuLiResp<- Numeric_responses #adds responses as numeric
Tdata$Char <- d[1:11] #adds background characteristics of respondents
Tdata$MostImpObst <- Create_NumericLickertScale(d[, i_MostImpObst], char_obst, 1:dim(as.matrix(char_obst))[1])
Tdata$MostImpResp <- Create_NumericLickertScale(d[, i_MostImpResp], char_resp, 1:dim(as.matrix(char_resp))[1])
#Recoding "most importants" by changing their levels;
#then placing the recoded data in the new matrix
#Doing something similar for the 2-degree, 1.5-degree, and 3-degree confidence questions.
#NA means "did not answer," then scale goes from 1-5 w/ "very low confidence"
#as 1 and "very high confidence" as 5
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees15 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees2 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees3 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....
#Lastly adding the various scales and short-hands
Tdata$likert_scales <- likert_scales
Tdata$confidence_levels <- confidence_levels
Tdata$short_responses <- short_responses
Tdata$short_obstacles <- short_obstacles
Tdata$scales <- scales
Tdata$char_resp <- char_resp
Tdata$char_obst <- char_obst
library(mlogit)
library(mnlogit)
data(Tdata$MostImpObst = "mnlogit")
data(Tdata$MostImpObst, package = "mnlogit")
table(Tdata$MostImpObst)
data(Tdata$MostImpObst, package = "mnlogit")
test <- data(Tdata, package = "mnlogit")
Tdata$MostImpObst <- as.factor(Tdata$MostImpObst)
Tdata$MostImpResp <- as.factor(Tdata$MostImpResp)
View(d)
long_obstacles <- reshape(Tdata,
varying = Tdata$MostImpObst,
v.names = "obstacles",
timevar = "choices",
times = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10",
"11", "12", "13", "14"),
new.row.names = 1:752,
direction = "long")
df <- data.frame(Tdata$Char,Tdata$MostImpResp)
remove(df)
df <- data.frame(Tdata$Char,Tdata$MostImpObst)
Tdata_mlogit <- mlogit.data(df, choice = "MostImpObst", shape = "wide")
Tdata_mlogit <- mlogit.data(df, choice = MostImpObst, shape = "wide")
Tdata_mlogit <- mlogit.data(df, choice = Tdata.MostImpObst, shape = "wide")
names(df)
Tdata_mlogit <- mlogit.data(df, choice = Tdata.MostImpObst, shape = "wide")
Tdata_mlogit <- mlogit.data(df, choice = 'Tdata.MostImpObst', shape = "wide")
View(Tdata_mlogit)
mnl_obstacles <- data.frame(Tdata$Char,Tdata$MostImpObst)
mnl_obstacles <- mlogit.data(mnl_obstacles, choice = Tdata.MostImpObst, shape = "wide")
mnl_obstacles <- mlogit.data(mnl_obstacles, choice = 'Tdata.MostImpObst', shape = "wide")
View(mnl_obstacles)
df_mlogit_obstacles <- data.frame(Tdata$Char,Tdata$MostImpObst)
df_mlogit_obstacles <- mlogit.data(df_mlogit_obstacles, choice = 'Tdata.MostImpObst', shape = "wide")
?mlogit
library(mlogit)
m1_obstacles <- mlogit(df_mlogit_obstacles$Tdata.MostImpObst ~ df_mlogit_obstacles$My.gender.is..., reflevel = '14' )
m1_obstacles <- mlogit(Tdata.MostImpObst ~ My.gender.is..., data = df_mlogit_obstacles,
reflevel = '14' )
m1_obstacles <- mlogit(Tdata.MostImpObst ~ My.gender.is..., H, data = df_mlogit_obstacles,
reflevel = '14' )
m1_obstacles <- mlogit(Tdata.MostImpObst ~ My.gender.is..., data = df_mlogit_obstacles,
reflevel = '14' )
?na.action
?mlogit.data
is.true(df_mlogit_obstacles$Tdata.MostImpObst)
table(Tdata$MostImpObst)
View(d)
Tdata$MostImpObst
?mlogit
m1_obstacles <- mlogit(Tdata.MostImpObst ~ My.gender.is..., data = df_mlogit_obstacles,
reflevel = '14', alt.subset = c("1", "2", "3", "4", "5", "6", "7", "8",
"9", "10", "11", "12", "13", "14") )
df_MostImpObst <- data.frame(Tdata$Char,Tdata$MostImpObst)
df_MostImpObst <- mlogit.data(df_MostImpObst,
choice = 'Tdata.MostImpObst', shape = "wide")
df_MostImpObst <- data.frame(Tdata$Char,Tdata$MostImpObst)
df_MostImpObst <- mlogit.data(df_MostImpObst,
choice = 'Tdata.MostImpObst', shape = "long")
View(df_MostImpObst)
remove(df_MostImpObst)
df_MostImpObst <- data.frame(Tdata$Char,Tdata$MostImpObst)
df_MostImpObst <- mlogit.data(df_MostImpObst,
choice = 'Tdata.MostImpObst', shape = "wide")
View(df_MostImpObst)
m1_obstacles <- mlogit(Tdata.MostImpObst ~ My.gender.is..., data = df_MostImpObst,
reflevel = '14', alt.subset = c("1", "2", "3", "4", "5", "6", "7", "8",
"9", "10", "11", "12", "13", "14") )
m1_obstacles <- mlogit(Tdata.MostImpObst ~ My.educational.background.is..., data = df_MostImpObst,
reflevel = '14', alt.subset = c("1", "2", "3", "4", "5", "6", "7", "8",
"9", "10", "11", "12", "13", "14") )
?mlogit.data
remove(df_MostImpObst)
df_MostImpObst <- data.frame(Tdata$Char,Tdata$MostImpObst
View(d_MostImpObst)
rm(list = ls())
source('lib_Create_NumericLickertScale.R')
source('lib_Correlation_matrix.R')
source('lib_Chi_squared.R')
source('lib_means_sds.R')
source('lib_plot_histograms.R')
source('lib_create_histogram.R')
source('lib_plot_MostImportant.R')
source('lib_degree_targets.R')
#reading in data as an xlsx sheet
d <- read.csv('survey20161209.csv', sep=",",stringsAsFactors = T) #unedited version
#what is the likert scale and in which numeric values should it be converted?
likert_scales <- c("Not Important", "Somewhat Important", "Moderately Important",
"Very Important", "Extremely Important")
scales<- 1:dim(array(likert_scales))
confidence_levels <- c("Very low confidence", "Low confidence", "Medium confidence",
"High confidence", "Very high confidence")
# what are the obstacles/responses written out=
char_obst<- c("(1) Uncertainty about climate change impacts or costs of mitigation",
"(2) Lack of public awareness about the magnitude of climate change impacts",
"(3)Â Different costs and benefits of mitigation across countries",
"(4) Time lag between costs and benefits of mitigation",
"(5) Different understandings of fairness and responsibility" ,
"(6) Concerns over high mitigation costs slowing economic development",
"(7) Uncertainty and risks about low-carbon technologies",
"(8)Â Negative greenhouse-gas emission externality from economic activity",
"(9) Consumerism in society",
"(10) Lack of administrative capacity for climate policy",
"(11) Opposition from special interest groups (for example emission-intensive industries)",
"(12) Global public-good nature of mitigation and free-riding incentives",
"(13) Multitude and complexity ofÂ obstacles",
"There is no \"most important\" obstacle" )
char_resp <- c("(1) More research on climate-change impacts or mitigation costs",
"(2) Intensified communication and education to build public support",
"(3) Financial and technological transfers between countries",
"(4) Compensation to special interest groups (for example, emission-intensive industries)",
"(5) Policies addressing intergenerational conflict (for example, appropriate discounting)",
"(6) Research and developmentÂ for low-carbon technologies",
"(7) Subsidies and standards to deploy low-carbon technologies",
"(8) Carbon pricing",
"(9) Change lifestyles and behaviors within society",
"(10) Strengthening domestic administrative capacity for climate policy",
"(11) Measures to enforce international emissions reductions (for example, trade sanctions)",
"(12) Applying concepts for human development other than growth of GDP",
"(13)Â Coherent and multi-objective policy packages",
"There is no \"most important\" response" )
#short names for obstacles/responses:
short_obstacles <- c("Scientific uncertainty", "Awareness", "Diff costs/benefits",
"Time lag b/t costs/benefits", "Understandings of fairness",
"Development concerns", "Technological uncertainty", "Emissions externality",
"Consumerism", "Lack of capacity", "Special interests",
"Free-riding", "Complexity")
short_responses <- c("More research", "More communication/education", "Monetary/tech transfers",
"Compensation to special interests", "Intragenerational policies",
"Technological R&D", "Tech subsidies/standards", "Carbon pricing",
"Behavior/lifestyle change", "Strengthen capacity", "International enforcement",
"Alt economic measures", "Multi-obj policy packages")
#dropping unneeded columns
d$StartDate <- NULL
d$CollectorID <- NULL
d$EndDate <- NULL
d$Email.Address <- NULL
d$First.Name <- NULL
d$LastName <- NULL
d$IP.Address <- NULL
d$Custom.Data <- NULL
#in which columns are obstacles/responses?
vec_obstacles<- 12:24
vec_responses<- 29:41
i_MostImpObst <- 25
i_MostImpResp <- 42
#########        Prepare data for analysis: convert string Lickert Scales to numeric values       #############
# for obstacles
Numeric_obstacles <- Create_NumericLickertScale(d[vec_obstacles], likert_scales, scales)#, as.character(1:dim(array(vec_obstacles))) )
# for responses:
Numeric_responses <- Create_NumericLickertScale(d[vec_responses], likert_scales, scales)#, as.character(1:dim(array(vec_responses)) ) )
# for "most important obstacles"
d_MostImpObst <- data.frame(table(d$X.span.style..font.size..18pt...Of.the.obstacles.identified.above..which.is.the.most.important.obstacle.to.address...span.))
# for "most important responses"
d_MostImpResp <- data.frame(table(d$Of.the.responses.listedÂ.above..which.is.the.most.important.))
# for confidence of achieving 2-degree target
d_2degrees <- data.frame(table(d$How.confident.are.you.that.the.world.can.keep.the.temperature.increase.below.2Â.C...),stringsAsFactors=FALSE)
# for confidence of achieving 1.5-degree target
d_1.5degrees <- data.frame(table(d$How.confident.are.you.that.the.world.can.keep.the.temperature.increase.below.1.5Â.C...))
###########creating the single, go-to matrix w/all numeric data and scales ###################
Tdata <- matrix(,nrow=0, ncol=0)
Tdata$NuLiObst<- Numeric_obstacles #adds obstacles as numeric
Tdata$NuLiResp<- Numeric_responses #adds responses as numeric
Tdata$Char <- d[1:11] #adds background characteristics of respondents
Tdata$MostImpObst <- Create_NumericLickertScale(d[, i_MostImpObst], char_obst, 1:dim(as.matrix(char_obst))[1])
Tdata$MostImpResp <- Create_NumericLickertScale(d[, i_MostImpResp], char_resp, 1:dim(as.matrix(char_resp))[1])
#Recoding "most importants" by changing their levels;
#then placing the recoded data in the new matrix
#Doing something similar for the 2-degree, 1.5-degree, and 3-degree confidence questions.
#NA means "did not answer," then scale goes from 1-5 w/ "very low confidence"
#as 1 and "very high confidence" as 5
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees15 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.1.5Â.C....
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees2 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.2Â.C....
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....)
levels(d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....) <- as.factor(c(NA,4,2,3,5,1))
Tdata$degrees3 <- d$How.confident.are.you.that.the.world.can.keep.global.average.temperature.increase.below.3Â.C....
#Lastly adding the various scales and short-hands
Tdata$likert_scales <- likert_scales
Tdata$confidence_levels <- confidence_levels
Tdata$short_responses <- short_responses
Tdata$short_obstacles <- short_obstacles
Tdata$scales <- scales
Tdata$char_resp <- char_resp
Tdata$char_obst <- char_obst
Tdata$MostImpObst <- as.factor(Tdata$MostImpObst)
Tdata$MostImpResp <- as.factor(Tdata$MostImpResp)
df_MostImpObst <- data.frame(Tdata$Char,Tdata$MostImpObst)
df_MostImpObst <- mlogit.data(df_MostImpObst,
choice = 'Tdata.MostImpObst', shape = "wide",
varying = 1:11, alt.levels = c("1", "2", "3", "4",
"5", "6", "7", "8",
"9", "10", "11", "12",
"13", "14"))
df_MostImpObst <- mlogit.data(df_MostImpObst,
choice = 'Tdata.MostImpObst', shape = "wide",
alt.levels = c("1", "2", "3", "4",
"5", "6", "7", "8",
"9", "10", "11", "12",
"13", "14"))
View(df_MostImpObst)
m1_obstacles <- mlogit(Tdata.MostImpObst ~ My.educational.background.is..., data = df_MostImpObst,
reflevel = '14')
m1_obstacles <- mlogit(Tdata.MostImpObst ~ My.educational.background.is...,
data = df_MostImpObst,
reflevel = '14')
?mlogit
m1_obstacles <- mlogit(Tdata.MostImpObst ~ My.educational.background.is...,
data = df_MostImpObst,
reflevel = '14', alt.subset = c("1", "2", "3", "4",
"5", "6", "7", "8", "9", "10", "11", "12", "13", "14"))
library(foreign) #essential for this
library(nnet) #essential for this because it contains the multinom function used
#to actually estimate the model
library(reshape2) #essential for this
Tdata$MostImpObst2 <- relevel(Tdata$MostImpObst, ref = '14')
test <- multinom(Tdata$MostImpObst2 ~ Tdata$Char[,4])
Tdata$econ <- Tdata$Char[,4] == 'Economics'
test2 <- multinom(Tdata$MostImpObst2 ~ Tdata$econ)
is.factor(Tdata$MostImpObst2)
rm(list = ls())
setwd('C:/Users/Chris/Documents/GitHub/final_paper')
source("cleaning_final.R")
library(stargazer)
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text',
dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 1: Log Odds Across Four Generations")
library(knitr)
conf_intervals <- cbind(confint(M_genY), confint(M_genX), confint(M_boomer),
confint(M_silent))
conf_intervals <- round(conf_intervals, digits = 3)
conf_intervals <- as.data.frame(conf_intervals)
colnames(conf_intervals) <- c(1, 2, 3, 4, 5, 6, 7, 8)
conf_intervals$gen_Y <- paste(conf_intervals$`1`, conf_intervals$`2`, sep=",")
conf_intervals$gen_X <- paste(conf_intervals$`3`, conf_intervals$`4`, sep=",")
conf_intervals$boomer <- paste(conf_intervals$`5`, conf_intervals$`6`, sep=",")
conf_intervals$silent <- paste(conf_intervals$`7`, conf_intervals$`8`, sep=",")
conf_intervals_kab <- cbind(conf_intervals$gen_Y, conf_intervals$gen_X,
conf_intervals$boomer, conf_intervals$silent)
kable(conf_intervals_kab, format = 'markdown', col.names = c("Gen Y",
"Gen X", "Boomer", "Silent"),
caption = "Figure 2: Confidence Intervals of Log Odds")
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text', apply.coef = exp,
dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 3: Odds Ratios Across Four Generations")
conf_intervals_exp <- cbind(exp(confint(M_genY)), exp(confint(M_genX)),
exp(confint(M_boomer)), exp(confint(M_silent)))
conf_intervals_exp <- round(conf_intervals_exp, digits = 3)
conf_intervals_exp <- as.data.frame(conf_intervals_exp)
colnames(conf_intervals_exp) <- c(1, 2, 3, 4, 5, 6, 7, 8)
conf_intervals_exp$gen_Y <- paste(conf_intervals_exp$`1`, conf_intervals_exp$`2`, sep=",")
conf_intervals_exp$gen_X <- paste(conf_intervals_exp$`3`, conf_intervals_exp$`4`, sep=",")
conf_intervals_exp$boomer <- paste(conf_intervals_exp$`5`, conf_intervals_exp$`6`, sep=",")
conf_intervals_exp$silent <- paste(conf_intervals_exp$`7`, conf_intervals_exp$`8`, sep=",")
conf_intervals_exp_kab <- cbind(conf_intervals_exp$gen_Y, conf_intervals_exp$gen_X,
conf_intervals_exp$boomer, conf_intervals_exp$silent)
kable(conf_intervals_exp_kab, format = 'markdown', col.names = c("Gen Y", "Gen X",
"Boomers", "Silent"),
caption = "Figure 4: Confidence Intervals of Odds Ratios")
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text', apply.coef = exp,
dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 3: Odds Ratios Across Four Generations",
se=list(NA, NA, NA, NA))
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text', apply.coef = exp,
dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 3: Odds Ratios Across Four Generations",
se=list(NA, NA, NA, NA), omit.table.layout = "n")
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text',
dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 1: Log Odds Across Four Generations",
ci = T)
kable(conf_intervals_kab, format = 'markdown', col.names = c("Gen Y",
"Gen X", "Boomer", "Silent"),
caption = "Figure 2: Confidence Intervals of Log Odds")
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text', apply.coef = exp,
dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 3: Odds Ratios Across Four Generations",
se=list(NA, NA, NA, NA), omit.table.layout = "n", ci = T)
View(conf_intervals_exp)
?apply.coef
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text', apply.coef = exp,
apply.se = exp, dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 3: Odds Ratios Across Four Generations")
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text', apply.coef = exp,
t.auto=F, p.auto=F, report = "vct*",
dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 3: Odds Ratios Across Four Generations")
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text',
dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 1: Log Odds Across Four Generations",
ci = T)
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text',
dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 1: Log Odds Across Four Generations",
ci = T, se = T)
stargazer(M_genY, M_genX, M_boomer, M_silent, type = 'text', apply.coef = exp,
t.auto=F, p.auto=F, report = "vct*",
dep.var.labels = "Probability of voting in 2012",
column.labels = c("Gen Y", "Gen X", "Boomers", "Silent"),
title = "Figure 3: Odds Ratios Across Four Generations")
